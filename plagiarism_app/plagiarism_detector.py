import requests
import frappe
import cv2
import json
import numpy as np
import faiss
import os
import torch
import pika  # RabbitMQ library for feedback
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image

# Define the image storage directory
image_directory = frappe.get_site_path('private', 'files', 'submitted_images')

# Create the directory if it doesn't exist
if not os.path.exists(image_directory):
    os.makedirs(image_directory)

# Load pre-trained ResNet50 model
resnet = models.resnet50(pretrained=True)
resnet.eval()  # Set to evaluation mode

# Define the transform for input images
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Function to connect to RabbitMQ plagiarism feedback queue
def connect_to_feedback_queue():
    rabbitmq_feedback_config = {
        'host': 'armadillo.rmq.cloudamqp.com',
        'port': 5672,
        'virtual_host': 'fzdqidte',
        'username': 'fzdqidte',
        'password': '0SMrDogBVcWUcu9brWwp2QhET_kArl59',
        'queue': 'plagiarism_feedback_queue'  # Queue for feedback
    }
    credentials = pika.PlainCredentials(rabbitmq_feedback_config['username'], rabbitmq_feedback_config['password'])
    connection = pika.BlockingConnection(pika.ConnectionParameters(
        host=rabbitmq_feedback_config['host'],
        port=rabbitmq_feedback_config['port'],
        virtual_host=rabbitmq_feedback_config['virtual_host'],
        credentials=credentials))
    return connection

# Function to publish feedback to RabbitMQ
def send_plagiarism_feedback(image_id, plagiarism_flag, similarity_score, cluster_id):
    connection = connect_to_feedback_queue()
    channel = connection.channel()
    
    # Declare the feedback queue with durability enabled
    channel.queue_declare(queue='plagiarism_feedback_queue', durable=True)

    # Convert similarity_score to a standard Python float if it exists
    if similarity_score is not None:
        similarity_score = float(similarity_score)

    # Prepare message to send
    feedback_message = {
        "image_id": image_id,
        "plagiarism_flag": plagiarism_flag,
        "similarity_score": similarity_score,
        "cluster_id": cluster_id
    }

    # Publish message to plagiarism_feedback_queue, making the message persistent
    channel.basic_publish(
        exchange='',
        routing_key='plagiarism_feedback_queue',
        body=json.dumps(feedback_message),
        properties=pika.BasicProperties(
            delivery_mode=2  # Make the message persistent
        )
    )
    
    # Close connection
    connection.close()

# Function to download the image and save it locally in the private folder
def download_image(img_url, submission_id):
    response = requests.get(img_url)
    if response.status_code == 200:
        image_path = os.path.join(image_directory, f"{submission_id}.jpg")
        with open(image_path, 'wb') as f:
            f.write(response.content)
        return image_path
    else:
        frappe.throw(f"Failed to download image from {img_url}")

# Function to save the image as an attachment in the Frappe File Doctype
def attach_image_to_doc(image_path, submission_id):
    with open(image_path, 'rb') as filedata:
        file_doc = frappe.get_doc({
            "doctype": "File",
            "file_name": f"{submission_id}.jpg",
            "attached_to_doctype": "Image Metadata",
            "attached_to_name": submission_id,
            "is_private": 1,
            "content": filedata.read(),
        })
        file_doc.save()
        frappe.db.commit()
        return file_doc.file_url  # Return the file URL generated by Frappe

# Function to extract feature vector using ResNet-50
def extract_feature_vector(image_path):
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0)  # Create batch dimension

    # Extract features from the last layer before classification
    with torch.no_grad():
        features = resnet(image_tensor)
    return features.numpy().flatten()  # Flatten to 1D feature vector

# Function to check for plagiarism by comparing feature vectors with FAISS
def check_for_plagiarism(image_id, feature_vector):
    # Load all existing feature vectors from Image Metadata
    image_docs = frappe.get_all('Image Metadata', fields=['feature_vector', 'name'])
    vectors = [json.loads(doc.feature_vector) for doc in image_docs if doc.feature_vector]
    vectors = np.array(vectors).astype('float32')

    # Create or load FAISS index
    if vectors.shape[0] > 0:
        index = faiss.IndexFlatL2(len(feature_vector))
        index.add(vectors)

        # Perform similarity search
        distances, indices = index.search(np.array([feature_vector]).astype('float32'), k=5)  # Top 5 matches
        return distances[0], indices[0]
    return None, None

# Main function to process image submission
def process_image_submission(submission_data):
    submission_id = submission_data.get("submission_id")
    img_url = submission_data.get("img_url")
    student_id = submission_data.get("student_id")

    # Step 1: Check if img_url is present
    if not img_url:
        frappe.logger().warning(f"Missing img_url for submission ID: {submission_id}, skipping...")
        return  # Skip processing this submission if img_url is missing

    # Step 2: Download the image and store it locally
    image_path = download_image(img_url, submission_id)

    # Step 3: Extract feature vector using ResNet-50
    feature_vector = extract_feature_vector(image_path)

    # Step 4: Attach the image to the Image Metadata Doctype and get the file URL
    file_url = attach_image_to_doc(image_path, submission_id)

    # Step 5: Save the image metadata and get the image document ID (name)
    image_doc = frappe.get_doc({
        "doctype": "Image Metadata",
        "submission_id": submission_id,  # Save submission_id for external reference
        "image_file": file_url,  # Store the file URL in the Attach field
        "upload_date": frappe.utils.now_datetime(),
        "student_id": student_id,
        "feature_vector": json.dumps(feature_vector.tolist())  # Store feature vector as JSON
    })
    image_doc.insert()
    frappe.db.commit()

    image_id = image_doc.name  # The Frappe Image Metadata document ID

    # Step 6: Check for plagiarism
    distances, indices = check_for_plagiarism(image_id, feature_vector)

    # Log the distances for debugging
    frappe.logger().info(f"Plagiarism Check - Distances: {distances}, Indices: {indices}")

    # Step 7: Handle plagiarism detection results
    threshold = 0.95  # Set a more sensitive threshold for plagiarism detection
    if distances is not None and len(distances) > 0:
        plagiarism_detected = False
        for i, distance in enumerate(distances):
            frappe.logger().info(f"Checking image {indices[i]} with distance {distance}")
            if distance < threshold:
                # Plagiarism detected
                plagiarism_detected = True
                similar_image_doc = frappe.get_doc("Image Metadata", indices[i])
                frappe.get_doc({
                    "doctype": "Plagiarism Flag",
                    "image_id": image_id,  # Use the Frappe document ID
                    "cluster_id": similar_image_doc.cluster_id,
                    "flag_date": frappe.utils.now_datetime(),
                    "review_status": "Pending"
                }).insert()

    # Clean up: Optionally delete the local image file after processing
    if os.path.exists(image_path):
        os.remove(image_path)
